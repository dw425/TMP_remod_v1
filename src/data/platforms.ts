import type { Platform } from '@/types/migration';

export const platforms: Platform[] = [
  {
    id: 'gcp',
    slug: 'gcp',
    name: 'Google Cloud',
    brandColor: '#4285F4',
    description: 'Migrate BigQuery, Dataflow, and Composer pipelines to Databricks.',
    tag: 'Cloud Platform',
    logo: 'https://upload.wikimedia.org/wikipedia/commons/5/51/Google_Cloud_logo.svg',
    logoType: 'url',
  },
  {
    id: 'redshift',
    slug: 'redshift',
    name: 'AWS Redshift',
    brandColor: '#232F3E',
    description: 'Move Redshift clusters, Spectrum queries, and Glue jobs to Databricks.',
    tag: 'Data Warehouse',
    logo: 'https://upload.wikimedia.org/wikipedia/commons/9/93/Amazon_Web_Services_Logo.svg',
    logoType: 'url',
  },
  {
    id: 'informatica',
    slug: 'informatica',
    name: 'Informatica',
    brandColor: '#FF4D00',
    description: 'Convert Informatica PowerCenter and IICS mappings to Databricks.',
    tag: 'ETL & Integration',
    logo: '/images/infromatica.png',
    logoType: 'url',
  },
  {
    id: 'snowflake',
    slug: 'snowflake',
    name: 'Snowflake',
    brandColor: '#29B5E8',
    description: 'Transition Snowflake data warehouses and pipelines to Databricks.',
    tag: 'Data Cloud',
    logo: 'https://upload.wikimedia.org/wikipedia/commons/f/ff/Snowflake_Logo.svg',
    logoType: 'url',
  },
  {
    id: 'teradata',
    slug: 'teradata',
    name: 'Teradata',
    brandColor: '#F37421',
    description: 'Transition Teradata data warehouses and BTEQ scripts to Databricks.',
    tag: 'Enterprise Data Warehouse',
    logo: '/images/teradata.png',
    logoType: 'url',
  },
  {
    id: 'unity-catalog',
    slug: 'unity-catalog',
    name: 'Unity Catalog',
    brandColor: '#FF3621',
    description: 'Consolidate Hive metastores and external catalogs into Unity Catalog.',
    tag: 'Metastore Upgrade',
    logo: 'https://upload.wikimedia.org/wikipedia/commons/6/63/Databricks_Logo.png',
    logoType: 'url',
  },
  {
    id: 'sap',
    slug: 'sap',
    name: 'SAP',
    brandColor: '#008FD3',
    description: 'Migrate SAP ERP, BW, and HANA workloads to Databricks Lakehouse.',
    tag: 'ERP / BW',
    logo: 'https://upload.wikimedia.org/wikipedia/commons/5/59/SAP_2011_logo.svg',
    logoType: 'url',
  },
  {
    id: 'synapse',
    slug: 'synapse',
    name: 'Azure Synapse',
    brandColor: '#0078D4',
    description: 'Migrate Synapse dedicated pools, pipelines, and Spark notebooks.',
    tag: 'Analytics',
    logo: 'https://upload.wikimedia.org/wikipedia/commons/f/fa/Microsoft_Azure.svg',
    logoType: 'url',
  },
  {
    id: 'sql-server',
    slug: 'sql-server',
    name: 'SQL',
    brandColor: '#737373',
    description: 'Migrate SQL Server databases, SSIS packages, and SSRS reports.',
    tag: 'Microsoft SQL Server',
    logo: 'https://upload.wikimedia.org/wikipedia/commons/4/44/Microsoft_logo.svg',
    logoType: 'url',
  },
  {
    id: 'oracle',
    slug: 'oracle',
    name: 'Oracle',
    brandColor: '#C74634',
    description: 'Migrate Oracle databases, PL/SQL, and ETL workflows to Databricks.',
    tag: 'Database',
    logo: 'https://upload.wikimedia.org/wikipedia/commons/5/50/Oracle_logo.svg',
    logoType: 'url',
  },
  {
    id: 'talend',
    slug: 'talend',
    name: 'Talend',
    brandColor: '#FF6D70',
    description: 'Convert Talend jobs and data integration flows to Databricks workflows.',
    tag: 'Data Integration',
    logoType: 'svg-text',
  },
];

export function getPlatformBySlug(slug: string): Platform | undefined {
  return platforms.find((p) => p.slug === slug);
}
